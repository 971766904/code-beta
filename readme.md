# HL-2A高β破裂

## 1.shot-choose
   - EFIT数据不一定完整（在结束时间点前就没有了）
   - disruptions1.xlsx是破裂或结束时间点，第一列炮号，第二列是否破裂，第三列破裂或结束时间点
   - 训练集测试集划分```np.random.shuffle(dis_shot)```
   - 需要增加验证集
## 2. data_process
   - 部分炮时间不足100ms
   - `'BOLU05'`和`‘SX04’`信号错误
   - boloU中心为`BOLU10`，boloD中心为`BOLOD09`sx中心为`SX10`或`SX11`
   - 使用信号：'Δip', 'βN', "I_HA_N", "V_LOOP", "BOLD03", "BOLD06", "BOLU03",                                                       
                "BOLU06", "SX03", "SX06", "EFIT_BETA_T", "EFIT_BETA_P",
                "EFIT_ELONGATION", "EFIT_LI", "EFIT_Q0", "EFIT_QBDRY",
                "BT", "DENSITY", "W_E", "FIR01", "FIR03"
   - 保存数据文件名：topdata_train.csv， topdata_test.csv
## 3. LightGBM_trainning
   - 利用sklearn.model_selection.train_test_split将训练集样本点分为训练和验证两部分，
   - 由于破裂样本点占比0.02211840462832425，模型可能过拟合了，可以对样本进行平衡
   - 保存模型名：model_1.txt
## 4. test_analysis_shot
   - 测试集评估，roc曲线，xue_assess函数使用了薛风鸣的评估方法（包括字典用法）
## 5. params_tuning & tuning_shot
   - 超参数调节
## 6. roc_compare
  - 比较不同模型的roc曲线
## 7. shap_analysis
  - 分析特征对破裂贡献度，包括相关性分析
## 8. shot_SHAP
  - 分析特征对每一炮的破裂贡献度
## 9.incremental_training
  - 用于增量学习训练探索
## 10.shot_signal_analysis
  - 用于对比每一炮的shap值变化，分析引起变化的输入特征
## 11.shap&signal_fig
  - 用于画出信号图与对应SHAP分析图结果
## 12.inference
  - 评估模型性能（包含对预警时间太短的炮判为fn）

## 训练思路
- 利用低β数据训练一个高效模型用高β数据来测试
- 利用低β数据加如少量高β数据来训练，用高β数据进行测试，对比两个模型性能
- 利用SHAP分析两个模型效果
- 模型L_H的bayes超参数调节：Final result: {'target': 0.9698326022737446, 'params': {'bagging_fraction': 0.7162422901102445,
'feature_fraction': 0.84974664157569, 'lambda_l1': 0.43612384651036784, 'lambda_l2': 0.9290120150434045, 'max_depth': 18.284715365630042, 'min_data_in_leaf': 103.20238402239872, 'num_leaves': 248.6658584137085}}
- 模型L_H_mix的bayes超参数调节：Final result: {'target': 0.9745799565131449, 'params': {'bagging_fraction': 0.7380101641257047, 'feature_fraction': 0.8645917930709374, 'lambda_l1': 0.030588791125829573, 'lambda_l2': 2.778394633628051, 'max_depth': 19.978169661804174, 'min_data_in_leaf': 165.14670031784632, 'num_leaves': 347.1316499103476}}
- 模型H的超参数调节：`'max_depth': 5,'num_leaves': 10,`
- 模型L_H的超参数调节：`'max_depth': 5,'num_leaves': 20,`
- 数据集LHdatabase
  - H_beta.npy包含所有高β炮号（βN>1)
  - L_beta_train.npy、L_beta_val.npy、L_beta_test.npy包含所有低β
  - H_beta_mix.npy用于混合的10炮高β炮`[36389, 36590, 36712, 36720, 36827, 36940, 36972, 37009,
       37030, 37042]`
  - H_beta1.npy删除了10炮用于混合后的高β
  - L_H_mix_roc是L_H数据集roc数据
- 混合数据当前使用模型：modelL_H_mix9_100.txt
- 低β数据当前使用模型：model_L_5_20.txt
- Mix的H的权重调高一点，不能是L:H=10：1，多试几个比例，至少要试到平衡，甚至超过平衡(data:5/12)search_weight.py
  - 构造mix数据集，控制10炮的复制倍数或者调节weight，把它当作超参数寻找最优
  - 复制6倍:`{'num_leaves': 25, 'max_depth': 6}`/`{'num_leaves': 45, 'max_depth': 5}`
  - weight2.2:`{{'num_leaves': 70, 'max_depth': 6, 'k': 2.2}}`
- 试一下Mix炮数，2-20不同数量，文章里面可以写写一下这个结果(data:5/12)search_mix_shot_num.py
  - 构造mix数据集，控制mix的炮数，同样寻找最优
  - `{'num_leaves': 70, 'max_depth': 6, 'h': 7}`
- 扩大high-beta 测试数据集到100-120左右(data:5/12)`{'num_leaves': 30, 'max_depth': 6}-tpr:0.72,fpr:0.117,pre_time:203.08ms`
  - 排除用于mix的10炮，用剩下得数据重新构造高β数据集，要求测试集100-120
  - 重新数据集预处理
  - 由于训练集数量可能不够，重新建模性能可能不够好，重新超参数调节
  - roc、SHAP等分析都要有
  - 数据文件：`t1_H_beta_train.npy,t1_H_beta_val.npy,t1_H_beta_test.npy\
    t1_topdata_H_test.csv,t1_topdata_H_train.csv,t1_topdata_H_val.csv`
- SHAP单跑分析结合真是信号，图要处理一下，原始数据直接画的图不好看，要缩放+平滑一下
  - 筛选重要信号
- 选择最优的混合高β破裂与非破裂比例
  - 确认明显的高β破裂炮`[36387,36389,36391,36761,36765,36766,36767,36785,36790,36795,36797,36800,36801,36802,36803,36804,36805,36806,36825,36826,36827,36828,36830,36837,36838,36840,36846,36847,36848,36849,36850,36865,36866,36870,36871,36873,36888,36890,36891,36892,36893,36894,36897,36898,36899,36939,36941,36945,36946,36947,36948,36949,36964,36965,36966,36967,36968,36969,36970,36972,36981,36983,36992,37003,37004,37005,37007,37013,37014,37020,37021,37022,37023,37030,37031,37080]36690,36755,36823,36934,36963,36980,36984,36985,36988,37024,37040`
  - _**36964,36965,36966,36967,36968,36969,36970,36972**_不确定高β，破裂前比压下降
  - 错误efit炮**37047**
  - 数据文件：`rate_H_beta_train.npy`etc.
  - 破裂炮占比1/2-`[36389, 36590, 36712, 36720, 36827, 36940, 36972, 37009, 37030, 37042]`
  - 破裂炮占比1-`[36389,36827,36972,37030,36992,36892,36795,37080,36790,36804]{'num_leaves': 30, 'max_depth': 6}`
  - 破裂炮占比4/5-`[36389,36827,36590,37030,36992,36892,36795,37080,37042,36804]{'num_leaves': 25, 'max_depth': 6}`
  - 破裂炮占比3/5-`[36389,36827,36590,37030,36992,36940,36795,37080,37042, 36712]{'num_leaves': 25, 'max_depth': 6}`
  - 破裂炮占比2/5-`[37009,36827,36590,37030,36992,36940,36795,36944,37042, 36712]{'num_leaves': 25, 'max_depth': 6}`
  - 破裂炮占比1/5-`[37009,36680,36590,37030,36992,36940,37033,36944,37042, 36712]{'num_leaves': 30, 'max_depth': 6}`
  - 2022/6/1:从roc曲线看最优还是0.5占比，没有明显规律
- t2对输入特征进行修改：密度选择01和04；sx、bolu、bold选择中心道；加入DH、DV以及sx、bolu、bold剖面特征
  - 数据文件：`t2_topdata_L_beta.csv、t2_topdata_train.csv、t2_topdata_val.csv、t2_topdata_test.csv、t2_topdata_H_beta.csv、\
  t2_topdata_H_train.csv、t2_topdata_H_val.csv、t2_topdata_H_test.csv`
  - t2_topdata_H_beta.csv应该包含用于混合的炮
- JDA应用
  - 全特征变换0.671、部分特征变换0.677、无特征变换0.786（0.5auc：0.739）
  - 全数据集变换0.764（0.5auc:0.658）
- CORAL应用
  - 全数据集变换0.828（0.5auc:0.743）'num_leaves': 10,'max_depth': 4
  - 不加入目标域数据0.72（0.576）
  - 不变换加入目标域数据0.786（0.739）
  - dropout,破裂非破裂分开变换0.722(0.629)
- 时间窗构造探索
  - H是序列长度，f是时间窗长度，l是步长
  - H长的序列可以得到样本数为：`int((H-f)/l) +1`
  - 通常会在最后在多加一个窗，把最后不足f长的信息包含进去
  - H、f、l都是整数，避免浮点数运算带来的误差

## 训练日志
- 2022/7/8
  - 删减了8个重要性低的特征得到92特征模型`model_t2_win_L.txt`
- 2022/7/11
  - `model/model_t2_win_goss.txt`使用goss方法，但是在低β上仍然效果没有之前好
  - 使用dart得到的f1值也只在0.84-0.85
  
- 筛选在不同参数区间有明显差异或相同趋势的信号
  - 在训练中删除相反信号；保留相反信号删除相同信号
    - 选择相反信号，可以直接删除：1、删除"BOLD03", "BOLD06","BOLU03", "BOLU06" H-set-valid auc 0.787；2、全信号H-set-valid auc 0.818；3、删除 ,"
      DENSITY", "W_E", "FIR01", "FIR03" H-set-valid aud 0.715  

| signal drop                           | H-set-valid auc(mix)    | L-set-valid auc(L) | H-set-valid auc(L) | H-set-valid auc(H) |
|---------------------------------------|-------------------------|--------------------|--------------------|--------------------|
| "BOLD03", "BOLD06","BOLU03", "BOLU06" | 0.787     (tuning:0.82) | 0.872              | 0.682              | 0.925              |
| "DENSITY", "W_E", "FIR01", "FIR03"    | 0.715                   | 0.812              | 0.516              | 0.90               |
| \                                     | 0.818                   | 0.839              | 0.567              | 0.935              |
  - 针对数据样本点（训练集）进行筛选，只选择一部分数据进行训练
    - 读取training set的样本进行shap计算
    - 选择部分信号的shap值范围，以此来筛选训练集样本数；选择依据："BOLD03", "BOLD06","BOLU03", "BOLU06"的shap值接近0的数据
    - 根据混合模型进行shap分析筛选；根据低参数模型进行shap分析筛选(默认删除4个相反信号)
    
  | sample reserve shap value                  | depend on mix model | depend on L model |
|--------------------------------------------|---------------------|-------------------|
| -1<"BOLD03", "BOLD06","BOLU03", "BOLU06"<1 | 0.603               | 0.678             |
| -0.5<~<0.5                                 |                     | 0.719             |
| -1.5<~<1.5                                 |                     | 0.761             |
